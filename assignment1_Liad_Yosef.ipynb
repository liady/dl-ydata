{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment1-Liad-Yosef.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liady/dl-ydata/blob/master/assignment1_Liad_Yosef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "X4WWyW4tM2Ir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Theoretical Aspects - Assignment 1"
      ]
    },
    {
      "metadata": {
        "id": "u1ZXXN9lM2Is",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import sklearn\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2qwj-IZM2Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Much of the power of neural networks comes from the nonlinearity that is inherited in activation functions.  \n",
        "Show that a network of N layers that uses a linear activation function can be reduced into a network with just an input and output layers.\n"
      ]
    },
    {
      "metadata": {
        "id": "cpe8l_TMxoW9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If our network can be represented as $out = f_n\\circ f_{n-1}\\circ ...\\circ f_1 \\circ f_0 (input)$ where all $f_k$ are linear, then they can be represented as matrices $T_n$, and so we can define $T = \\prod T_n  $ and $output = T \\cdot input$"
      ]
    },
    {
      "metadata": {
        "id": "-e-VlB4eM2Iz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Derivatives of Activation Functions\n",
        "Compute the derivative of these activation functions:\n",
        "\n",
        "1 Sigmoid\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*Vo7UFksa_8Ne5HcfEzHNWQ.png\" width=\"150\">"
      ]
    },
    {
      "metadata": {
        "id": "poi3JjNdzgRH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$f'(t) = -e^{-t}*\\frac{-1}{(1+e^{-t})^2} = \\frac{e^{-t}}{(1+e^{-t})^2}= \\frac{1}{1+e^{-t}} * (1-\\frac{1}{1+e^{-t}})$ "
      ]
    },
    {
      "metadata": {
        "id": "z0AiF6YjM2I3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2 Relu \n",
        "\n",
        "<img src=\"https://cloud.githubusercontent.com/assets/14886380/22743194/73ca0834-ee54-11e6-903f-a7efd247406b.png\" width=\"200\">"
      ]
    },
    {
      "metadata": {
        "id": "lxzlpr-q0x4D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$f'(x) = \\left\\{\n",
        "\t\\begin{array}{ll}\n",
        "\t\t1  & \\mbox{if } x > 0 \\\\\n",
        "\t\t0 & \\mbox{if } x \\leq 0\n",
        "\t\\end{array}\n",
        "\\right.$"
      ]
    },
    {
      "metadata": {
        "id": "8tcbCKStM2I7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3 Softmax\n",
        "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3\" width=\"250\">"
      ]
    },
    {
      "metadata": {
        "id": "Q3rIIjDT1iqc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "sRE-pv-zM2I-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Back Propagation\n",
        "Use the delta rule and backprop to compute the derivatives for these computations:"
      ]
    },
    {
      "metadata": {
        "id": "3sJZ_0mWM2JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "z = x1 + 5*x2 - 3*x3^2\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "3jXlDkOi2bF2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$\n",
        "\\frac{\\delta z}{\\delta x_1} = 1\\\\\n",
        "\\frac{\\delta z}{\\delta x_2} = 5\\\\\n",
        "\\frac{\\delta z}{\\delta x_3} = -6x_3\\\\\n",
        "$"
      ]
    },
    {
      "metadata": {
        "id": "pgwnBRJgM2JD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "z = x1*(x2-4) + exp(x3^2) / 5*x4^2\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "cB9pbzAt23GY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "$\n",
        "\\frac{\\delta z}{\\delta x_1} = (x_2 - 4)\\\\\n",
        "\\frac{\\delta z}{\\delta x_2} = x_1\\\\\n",
        "\\frac{\\delta z}{\\delta x_3} = \\frac{2*x_3*e^(x_3 ^2)}{5*x_4^2}\\\\\n",
        "\\frac{\\delta z}{\\delta x_4} = -1*\\frac{e^(x_3^2)}{(5*x_4^2)^2}*10*x_4\n",
        "$"
      ]
    },
    {
      "metadata": {
        "id": "hCIx61WAM2JI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "z = 1/x3 + exp( (x1+5*(x2+3)) ^2 )\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "x0t9ocxlM2JM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sample convolutions\n",
        "Consider the following convolution filters:\n",
        "```python\n",
        "k1 = [ [0 0 0], [0 1 0], [0 0 0] ]\n",
        "k2 = [ [0 0 0], [0 0 1], [0 0 0] ]\n",
        "k3 = [ [-1-1 -1], [-1 8 -1], [-1 -1 -1] ]\n",
        "k4 = [ [1 1 1], [1 1 1], [1 1 1] ] / 9\n",
        "```\n",
        "\n",
        "Can you guess what each of them computes?"
      ]
    },
    {
      "metadata": {
        "id": "x3Xbnxrf4Ig8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "k1 = Takes only the middle pixel\n",
        "\n",
        "k2 = Takes only the \"middle\" pixel - but shifted to the right\n",
        "\n",
        "k3 = Enhanches the middle pixel (and decreases the others)\n",
        "\n",
        "k4 = Averages the pixels - blurs"
      ]
    },
    {
      "metadata": {
        "id": "QcwrzQguM2JN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Apply to arrays\n",
        "Apply the convolutions above to the following array:\n"
      ]
    },
    {
      "metadata": {
        "id": "_W0seUnYM2JO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array([\n",
        "       [-1, -3, -4,  0, -1],\n",
        "       [ 2, -2, -4,  0, -2],\n",
        "       [-3, -2,  2,  2,  3],\n",
        "       [ 0, -3, -4, -4, -2],\n",
        "       [-4, -2,  2,  0,  1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5LNrgDPJM2JQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def conv(input, kernel):\n",
        "  x = input.shape[0] - (kernel.shape[0] - 1)\n",
        "  y = input.shape[1] - (kernel.shape[1] - 1)\n",
        "  ret = np.zeros([x, y])\n",
        "  for i in range(x):\n",
        "    for j in range(y):\n",
        "      xrange = range(i, i + kernel.shape[0])\n",
        "      yrange = range(j, j + kernel.shape[1])\n",
        "      sliced = input[i:i + kernel.shape[0], j: j + kernel.shape[1]]\n",
        "      ret[i][j] = np.sum(sliced*kernel)\n",
        "  return ret\n",
        "\n",
        "x1 = conv(x, np.array( [ [0, 0, 0], [0, 1, 0], [0, 0, 0] ]))\n",
        "x2 = conv(x, np.array( [ [0, 0, 0], [0, 0, 1], [0, 0, 0] ]))\n",
        "x3 = conv(x, np.array( [ [-1, -1, -1], [-1, 8, -1], [-1, -1, -1] ]))\n",
        "x4 = conv(x, np.divide(np.array( [ [1, 1, 1], [1, 1, 1], [1, 1, 1] ]), 9))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWreTtHEM2JT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What would be the output dimensions in these cases?\n",
        "1. No padding, stride of 1\n",
        "1. No padding, stride of 2\n",
        "1. Zero padding, stride of 1\n",
        "1. Zero padding, stride of 2"
      ]
    },
    {
      "metadata": {
        "id": "NJAs_yMB-Rvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "1. (3, 3)\n",
        "\n",
        "2. (1, 1)\n",
        "\n",
        "3. (5, 5)\n",
        "\n",
        "4. (3, 3)"
      ]
    },
    {
      "metadata": {
        "id": "hn6zBCbhM2JV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Consider convolutions with kernels of size 3x3, 5x5, 7x7 etc.\n",
        "\n",
        "Come up with an equation for the dimension of the output image after a convolution layer. Your equation should also take into account padding and the stride."
      ]
    },
    {
      "metadata": {
        "id": "KIfmkghoM2JX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = input.shape[0] + padding[0] - (kernel.shape[0] -1 + 2 * (stride[0] - 1))\n",
        "Y = input.shape[1] + padding[1] - (kernel.shape[1] -1 + 2 * (stride[1] - 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuFv87kEM2Ja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Apply to images\n",
        "Apply the convolution filters above on the image. Plot the results:"
      ]
    },
    {
      "metadata": {
        "id": "foMgNADVM2Jb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "316b6725-06a0-4df4-be3b-e943db2f6504"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "im = mpimg.imread('./lena.jpg')\n",
        "plt.imshow(im)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-101139102062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./lena.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mpilread\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './lena.jpg'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "o6XAsGV4M2Jg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjUIz0pQM2Jk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Network dimensions\n",
        "Write below the dimensions and number of parameters in each layer of this network for the MNIST data:\n",
        "\n",
        "- Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
        "- Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
        "- Convolutional Layer #2: Applies 64 5x5 filters, with ReLU activation function\n",
        "- Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
        "- Dense Layer #1: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
        "- Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0â€“9).\n"
      ]
    },
    {
      "metadata": {
        "id": "3vSuawFaM2Jl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8-6p8KxM2Jn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Learning in biological neurons\n",
        "Try to come up with a learning algorithm for a neural network that replaces back propagation, and mimicks the operation of biological neurons."
      ]
    },
    {
      "metadata": {
        "id": "0vd8WQMHM2Jn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvTBLm44M2Jq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Puppy or bagel?\n",
        "We've seen in class the (hopefully) funny examples of challenging images (Chihuahua or muffin, puppy or bagel etc.). \n",
        "\n",
        "Let's say you were asked by someone to find more examples like that. You are able to call the 3 neural networks that won the recent ImageNet challenges, and get their predictions (the entire vector of probabilities for the 1000 classes).  \n",
        "\n",
        "Describe methods that might assist you in finding more examples."
      ]
    },
    {
      "metadata": {
        "id": "WsTYNPDvM2Jr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CIsnCby5M2Jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Gradient Checking\n",
        "When computing the gradient yourself, it's recommended to manually check the gradient to make sure you haven't made an error.  \n",
        "We'll use the following equation for this, which produces more robust results than the standard definition of a derivative:\n",
        "\n",
        "\n",
        "<img src=\"http://ufldl.stanford.edu/wiki/images/math/a/2/3/a23bea0ab48ded7b9a979b68f6356613.png\" width=\"250\">"
      ]
    },
    {
      "metadata": {
        "id": "PVqcckZwM2Jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll numerically approximate it using:\n",
        "\n",
        "<img src=\"http://ufldl.stanford.edu/wiki/images/math/4/8/a/48a000aed96c8595fcca2a45f48343ce.png\" width=\"250\">"
      ]
    },
    {
      "metadata": {
        "id": "_xAfbLz6M2Ju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Write a function that evaluates the gradient locally and use it to numerically compute the gradient along several randomly chosen dimensions. Compare your results with your analytically computed gradient. The numbers should match almost exactly along all dimensions."
      ]
    },
    {
      "metadata": {
        "id": "9q5tPe8JM2Ju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}