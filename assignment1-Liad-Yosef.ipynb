{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of assignment1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liady/dl-ydata/blob/master/assignment1-Liad-Yosef.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "X4WWyW4tM2Ir",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Learning Theoretical Aspects - Assignment 1"
      ]
    },
    {
      "metadata": {
        "id": "u1ZXXN9lM2Is",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import sklearn\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U2qwj-IZM2Iw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Much of the power of neural networks comes from the nonlinearity that is inherited in activation functions.  \n",
        "Show that a network of N layers that uses a linear activation function can be reduced into a network with just an input and output layers.\n"
      ]
    },
    {
      "metadata": {
        "id": "jmDcfgIOM2Ix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-e-VlB4eM2Iz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Derivatives of Activation Functions\n",
        "Compute the derivative of these activation functions:\n",
        "\n",
        "1 Sigmoid\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1200/1*Vo7UFksa_8Ne5HcfEzHNWQ.png\" width=\"150\">"
      ]
    },
    {
      "metadata": {
        "id": "bk-7BzFQM2I0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z0AiF6YjM2I3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "2 Relu \n",
        "\n",
        "<img src=\"https://cloud.githubusercontent.com/assets/14886380/22743194/73ca0834-ee54-11e6-903f-a7efd247406b.png\" width=\"200\">"
      ]
    },
    {
      "metadata": {
        "id": "BWTRtEX8M2I4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8tcbCKStM2I7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "3 Softmax\n",
        "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3\" width=\"250\">"
      ]
    },
    {
      "metadata": {
        "id": "0Qb8zeNBM2I8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sRE-pv-zM2I-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Back Propagation\n",
        "Use the delta rule and backprop to compute the derivatives for these computations:"
      ]
    },
    {
      "metadata": {
        "id": "3sJZ_0mWM2JA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "z = x1 + 5*x2 - 3*x3^2\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "yPXdNKsGM2JA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pgwnBRJgM2JD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "z = x1*(x2-4) + exp(x3^2) / 5*x4^2\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "gQ1igYpxM2JE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hCIx61WAM2JI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```\n",
        "z = 1/x3 + exp( (x1+5*(x2+3)) ^2 )\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "zSdvzQTlM2JJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x0t9ocxlM2JM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Sample convolutions\n",
        "Consider the following convolution filters:\n",
        "```python\n",
        "k1 = [ [0 0 0], [0 1 0], [0 0 0] ]\n",
        "k2 = [ [0 0 0], [0 0 1], [0 0 0] ]\n",
        "k3 = [ [-1-1 -1], [-1 8 -1], [-1 -1 -1] ]\n",
        "k4 = [ [1 1 1], [1 1 1], [1 1 1] ] / 9\n",
        "```\n",
        "\n",
        "Can you guess what each of them computes?"
      ]
    },
    {
      "metadata": {
        "id": "QcwrzQguM2JN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Apply to arrays\n",
        "Apply the convolutions above to the following array:\n"
      ]
    },
    {
      "metadata": {
        "id": "_W0seUnYM2JO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = np.array([[-1, -3, -4,  0, -1],\n",
        "       [ 2, -2, -4,  0, -2],\n",
        "       [-3, -2,  2,  2,  3],\n",
        "       [ 0, -3, -4, -4, -2],\n",
        "       [-4, -2,  2,  0,  1]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5LNrgDPJM2JQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWreTtHEM2JT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What would be the output dimensions in these cases?\n",
        "1. No padding, stride of 1\n",
        "1. No padding, stride of 2\n",
        "1. Zero padding, stride of 1\n",
        "1. Zero padding, stride of 2"
      ]
    },
    {
      "metadata": {
        "id": "1iy3ItrgM2JT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hn6zBCbhM2JV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Consider convolutions with kernels of size 3x3, 5x5, 7x7 etc.\n",
        "\n",
        "Come up with an equation for the dimension of the output image after a convolution layer. Your equation should also take into account padding and the stride."
      ]
    },
    {
      "metadata": {
        "id": "KIfmkghoM2JX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XuFv87kEM2Ja",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Apply to images\n",
        "Apply the convolution filters above on the image. Plot the results:"
      ]
    },
    {
      "metadata": {
        "id": "foMgNADVM2Jb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "im = mpimg.imread('lena.jpg')\n",
        "plt.imshow(im)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o6XAsGV4M2Jg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TjUIz0pQM2Jk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Network dimensions\n",
        "Write below the dimensions and number of parameters in each layer of this network for the MNIST data:\n",
        "\n",
        "- Convolutional Layer #1: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
        "- Pooling Layer #1: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
        "- Convolutional Layer #2: Applies 64 5x5 filters, with ReLU activation function\n",
        "- Pooling Layer #2: Again, performs max pooling with a 2x2 filter and stride of 2\n",
        "- Dense Layer #1: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
        "- Dense Layer #2 (Logits Layer): 10 neurons, one for each digit target class (0–9).\n"
      ]
    },
    {
      "metadata": {
        "id": "3vSuawFaM2Jl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D8-6p8KxM2Jn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Learning in biological neurons\n",
        "Try to come up with a learning algorithm for a neural network that replaces back propagation, and mimicks the operation of biological neurons."
      ]
    },
    {
      "metadata": {
        "id": "0vd8WQMHM2Jn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvTBLm44M2Jq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Puppy or bagel?\n",
        "We've seen in class the (hopefully) funny examples of challenging images (Chihuahua or muffin, puppy or bagel etc.). \n",
        "\n",
        "Let's say you were asked by someone to find more examples like that. You are able to call the 3 neural networks that won the recent ImageNet challenges, and get their predictions (the entire vector of probabilities for the 1000 classes).  \n",
        "\n",
        "Describe methods that might assist you in finding more examples."
      ]
    },
    {
      "metadata": {
        "id": "WsTYNPDvM2Jr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CIsnCby5M2Jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Gradient Checking\n",
        "When computing the gradient yourself, it's recommended to manually check the gradient to make sure you haven't made an error.  \n",
        "We'll use the following equation for this, which produces more robust results than the standard definition of a derivative:\n",
        "\n",
        "\n",
        "<img src=\"http://ufldl.stanford.edu/wiki/images/math/a/2/3/a23bea0ab48ded7b9a979b68f6356613.png\" width=\"250\">"
      ]
    },
    {
      "metadata": {
        "id": "PVqcckZwM2Jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll numerically approximate it using:\n",
        "\n",
        "<img src=\"http://ufldl.stanford.edu/wiki/images/math/4/8/a/48a000aed96c8595fcca2a45f48343ce.png\" width=\"250\">"
      ]
    },
    {
      "metadata": {
        "id": "_xAfbLz6M2Ju",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Write a function that evaluates the gradient locally and use it to numerically compute the gradient along several randomly chosen dimensions. Compare your results with your analytically computed gradient. The numbers should match almost exactly along all dimensions."
      ]
    },
    {
      "metadata": {
        "id": "9q5tPe8JM2Ju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}